apiVersion: flux.weave.works/v1beta1
kind: HelmRelease
metadata:
  name: stakater-delivery-chartmuseum
  namespace: delivery
spec:
  releaseName: stakater-delivery-chartmuseum
  chart:
    repository: https://kubernetes-charts.storage.googleapis.com
    name: chartmuseum
    version: 2.3.1
  values:
    replicaCount: 1
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 0    
    env:
      open:
        PROJECT_NAMESPACE: ${PROJECT_NAMESPACE}
        KUBERNETES_MASTER: https://kubernetes.default:443
        # storage backend, can be one of: local, alibaba, amazon, google, microsoft
        STORAGE: local
        # oss bucket to store charts for alibaba storage backend
        STORAGE_ALIBABA_BUCKET:
        # prefix to store charts for alibaba storage backend
        STORAGE_ALIBABA_PREFIX:
        # oss endpoint to store charts for alibaba storage backend
        STORAGE_ALIBABA_ENDPOINT:
        # server side encryption algorithm for alibaba storage backend, can be one
        # of: AES256 or KMS
        STORAGE_ALIBABA_SSE:
        # s3 bucket to store charts for amazon storage backend
        STORAGE_AMAZON_BUCKET:
        # prefix to store charts for amazon storage backend
        STORAGE_AMAZON_PREFIX:
        # region of s3 bucket to store charts
        STORAGE_AMAZON_REGION:
        # alternative s3 endpoint
        STORAGE_AMAZON_ENDPOINT:
        # server side encryption algorithm
        STORAGE_AMAZON_SSE:
        # gcs bucket to store charts for google storage backend
        STORAGE_GOOGLE_BUCKET:
        # prefix to store charts for google storage backend
        STORAGE_GOOGLE_PREFIX:
        # container to store charts for microsoft storage backend
        STORAGE_MICROSOFT_CONTAINER:
        # prefix to store charts for microsoft storage backend
        STORAGE_MICROSOFT_PREFIX:
        # container to store charts for openstack storage backend
        STORAGE_OPENSTACK_CONTAINER:
        # prefix to store charts for openstack storage backend
        STORAGE_OPENSTACK_PREFIX:
        # region of openstack container
        STORAGE_OPENSTACK_REGION:
        # path to a CA cert bundle for your openstack endpoint
        STORAGE_OPENSTACK_CACERT:
        # form field which will be queried for the chart file content
        # CHART_POST_FORM_FIELD_NAME: chart
        # form field which will be queried for the provenance file content
        # PROV_POST_FORM_FIELD_NAME: prov
        # levels of nested repos for multitenancy. The default depth is 0 (singletenant server)
        DEPTH: 0
        # show debug messages
        DEBUG: false
        # output structured logs as json
        # LOG_JSON: true
        # disable use of index-cache.yaml
        DISABLE_STATEFILES: false
        # disable Prometheus metrics
        # DISABLE_METRICS: true
        # disable all routes prefixed with /api
        DISABLE_API: false
        # allow chart versions to be re-uploaded
        ALLOW_OVERWRITE: true
        # absolute url for .tgzs in index.yaml
        CHART_URL:
        # allow anonymous GET operations when auth is used
        AUTH_ANONYMOUS_GET: true
        # sets the base context path
        CONTEXT_PATH:
        # parallel scan limit for the repo indexer
        INDEX_LIMIT: 0
        # cache store, can be one of: redis (leave blank for inmemory cache)
        CACHE:
        # address of Redis service (host:port)
        CACHE_REDIS_ADDR:
        # Redis database to be selected after connect
        CACHE_REDIS_DB: 0
      field:
        KUBERNETES_NAMESPACE: metadata.namespace
      secret:
        # username for basic http authentication
        # BASIC_AUTH_USER:
        # password for basic http authentication
        # BASIC_AUTH_PASS:
        # GCP service account json file
        GOOGLE_CREDENTIALS_JSON:
        # Redis requirepass server configuration
        CACHE_REDIS_PASSWORD:
    deployment:
      ## Chartmuseum Deployment annotations
      annotations:
        fluentd_configuration: >
          [
            [
              {
                "expression": "/(?<time>[^\t]+)\t(?<level>[^\t]+)\t(?<log>[^ ].*$)/",
                "time_format": "%iso8601",
                "container_name": "chartmuseum"
              }
            ]
          ]
      #   name: value
      labels:
        group: com.stakater.platform
        provider: stakater
        version: "v0.8.0"
      #   name: value
      matchlabes:
        app: chartmuseum
        group: com.stakater.platform
        provider: stakater
      #   name: value
    replica:
      ## Chartmuseum Replicas annotations
      annotations: {}
      ## Read more about kube2iam to provide access to s3 https://github.com/jtblin/kube2iam
      #   iam.amazonaws.com/role: role-arn
    service:
      servicename: chartmuseum
      type: ClusterIP
      # clusterIP: None
      externalPort: 80
      nodePort:
      annotations:
        config.xposer.stakater.com/Domain: REPLACE_DOMAIN_NAME
        config.xposer.stakater.com/IngressNameTemplate: '{{.Service}}-{{.Namespace}}'
        config.xposer.stakater.com/IngressURLTemplate: '{{.Service}}.{{.Namespace}}.{{.Domain}}'
        xposer.stakater.com/annotations: |-
          kubernetes.io/ingress.class: internal-ingress
          ingress.kubernetes.io/force-ssl-redirect: true
          ingress.kubernetes.io/proxy-body-size: 900m
          forecastle.stakater.com/expose: true
          forecastle.stakater.com/icon: https://cdn-images-1.medium.com/max/521/0*D__TQ7qMdoq3Y7kP.png
          forecastle.stakater.com/appName: Chartmuseum
          exposeIngressUrl: locally
      labels:
        expose: "true"

    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 80m
        memory: 64Mi

    probes:
      liveness:
        initialDelaySeconds: 5
        periodSeconds: 10
        timeoutSeconds: 1
        successThreshold: 1
        failureThreshold: 3
      readiness:
        initialDelaySeconds: 5
        periodSeconds: 10
        timeoutSeconds: 1
        successThreshold: 1
        failureThreshold: 3

    serviceAccount:
      create: false
      # name:

    securityContext: {}

    nodeSelector: {}

    tolerations:
    - key: "dedicated"
      operator: "Equal"
      value: "app"
      effect: "NoSchedule"

    affinity: {}

    persistence:
      enabled: true
      # labels:
      #   group: com.stakater.platform
      #   provider: stakater
      #   version: "0.7.2"
      # accessMode: ReadWriteOnce
      # size: 10Gi
      ## A manually managed Persistent Volume and Claim
      ## Requires persistence.enabled: true
      ## If defined, PVC must be created manually before volume will be bound
      existingClaim: stakater-delivery-chartmuseum 

      ## Chartmuseum data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      # storageClass: "efs"
      # volumeName:
      # pv:
      #   enabled: false
      #   pvname: testPvName
      #   capacity:
      #     storage: 10Gi
      #   accessMode: ReadWriteOnce
      #   nfs:
      #     server: testServer
      #     path: /Chartmuseum

    ## Ingress for load balancer
    ingress:
      enabled: false
    ## Chartmuseum Ingress labels
    ##
    #   labels:
    #     dns: "route53"

    ## Chartmuseum Ingress annotations
    ##
    #   annotations:
    #     kubernetes.io/ingress.class: nginx
    #     kubernetes.io/tls-acme: "true"

    ## Chartmuseum Ingress hostnames
    ## Must be provided if Ingress is enabled
    ##
    #   hosts:
    #     chartmuseum.domain.com:
    #         - /charts
    #         - /index.yaml

    ## Chartmuseum Ingress TLS configuration
    ## Secrets must be manually created in the namespace
    ##
    #   tls:
    #   - secretName: chartmuseum-server-tls
    #     hosts:
    #     - chartmuseum.domain.com

    # Adding secrets to tiller is not a great option, so If you want to use an existing
    # secret that contains the json file, you can use the following entries
    gcp:
      secret:
        enabled: false
        # Name of the secret that contains the encoded json
        name:
        # Secret key that holds the json value.
        key: credentials.json
